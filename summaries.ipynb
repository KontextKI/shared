{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=\"anything\",\n",
    "    base_url=\"http://0.0.0.0:4000\"\n",
    ")\n",
    "\n",
    "prompt_summary = \"Summarize the given Input in 30 to 40 words, and in the same language as the Input. Find all the keywords that are relevant to the summary from the input and use them. : {input}\"\n",
    "\n",
    "\n",
    "def get_summary(input, temp:float=0.7):\n",
    "    prompt = prompt_summary.format(input=input)\n",
    "    # request sent to model set on litellm proxy, `litellm --model`\n",
    "    response = client.chat.completions.create(model=\"llama3.2:1b\", temperature = temp, messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{prompt}\"\n",
    "        }\n",
    "    ])\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.json' , 'r') as f:\n",
    "    jj = json.loads(f.read())\n",
    "djj = pd.DataFrame(jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generarte summaries of documents in range at temperatures 0.0 and 0.7\n",
    "dj=djj.loc[ (djj['input'].str.len() > 3300) & (djj['input'].str.len() < 3700)].copy()\n",
    "dj['temp0'] = dj.input.apply(lambda x : get_summary(x, temp=0.0))\n",
    "dj['temp7'] = dj.input.apply(lambda x : get_summary(x, temp=0.7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the selfcheckgpt like scoring using a LLM\n",
    "\n",
    "text_mapping = {'yes': 0.0, 'no': 1.0, 'n/a': 0.5}\n",
    "prompt_score = \"Context: {context}\\n\\nSentence: {sentence}\\n\\nIs the sentence a good sumamry of the context above? Answer in yes or no only no punctuations either.\\n\\nAnswer: \"\n",
    "\n",
    "def get_score(input, output, prompt_score:str, temp:float=0.7):\n",
    "    prompt = prompt_score.format(sentence=input, context=output)\n",
    "    #messages=[{ \"content\": f\"{prompt}\", \"role\": \"user\"}] \n",
    "    response = client.chat.completions.create(model=\"gemma2:27b\", temperature = temp, messages = [\n",
    "        { \n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{prompt}\"\n",
    "        }\n",
    "    ])\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj['oscore'] =     dj.apply((lambda x : get_score(x['input'], x['output'], prompt_score=prompt_score)), axis=1)\n",
    "dj['oscore'] = dj.oscore.apply( lambda x : text_mapping[x.lower().strip()])\n",
    "\n",
    "dj['temp0_score'] = dj.apply((lambda x : get_score(x['input'], x['temp0'], prompt_score=prompt_score)), axis=1)\n",
    "dj['temp0_score'] = dj.temp0_score.apply( lambda x : text_mapping[x.lower().strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_score = \"Context: {context}\\n\\nSentence: {sentence}\\n\\nIs the sentence a good sumamry of the context above? Answer in yes or no only no punctuations either.\\n\\nAnswer: \"\n",
    "\n",
    "def get_score(input, output, prompt_score:str, temp:float=0.7):\n",
    "    prompt = prompt_score.format(sentence=input, context=output)\n",
    "    #messages=[{ \"content\": f\"{prompt}\", \"role\": \"user\"}] \n",
    "    response = client.chat.completions.create(model=\"gemma2:27b\", temperature = temp, messages = [\n",
    "        { \n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{prompt}\"\n",
    "        }\n",
    "    ])\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"Alibaba-NLP/gte-multilingual-base\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sbert_score(sentences):\n",
    "    embeddings = model.encode(sentences)\n",
    "    score =  model.similarity(embeddings, embeddings)\n",
    "    return pd.Series(score[0].tolist()[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input is the original document to summarize\n",
    "#output is the summary\n",
    "#temp0  and temp7 are summaries  generated at temperature 0.0 and 0.8\n",
    "dj[['score0', 'score1', 'score2']] = dj.apply((lambda x : get_sbert_score([x.input, x.output, x.temp0, x.temp7])), axis=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
